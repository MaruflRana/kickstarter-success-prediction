{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Kickstarter Success Prediction üöÄ**\n",
    "\n",
    "This Jupyter Notebook walks through the process of building a machine learning model to predict whether a Kickstarter campaign will be successful. We'll perform data loading, feature engineering, model training, and evaluation using a more granular, step-by-step approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**\n",
    "First, we import the necessary Python libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Data**\n",
    "Next, we load the Kickstarter dataset.\n",
    "\n",
    "**Important:** Update the `file_path` variable to the location of your `kickstarter.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTANT: Update this file path to match your file's location ---\n",
    "file_path = 'e:/ML_Project/kickstarter-success-prediction/data/kickstarter.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: The file '{file_path}' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Dataset Details & Initial Exploration**\n",
    "Let's get a better understanding of our dataset. This dataset contains information on thousands of Kickstarter campaigns, each with various attributes like the project's category, funding goal, launch date, and final status.\n",
    "\n",
    "Our goal is to use these attributes to predict the `binary_state` (successful or failed).\n",
    "\n",
    "First, a quick preview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the data types and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a concise summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Feature Engineering & Data Cleaning**\n",
    "In this step, we'll clean the data and create new features to improve our model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. Engineer New Features from Dates**\n",
    "We start by making a copy of the dataframe to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a clean copy to preserve the original dataframe\n",
    "df_processed = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we convert the `launched_at` column to a datetime object, which is necessary to extract time-based features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'launched_at' to a datetime object\n",
    "df_processed['launched_at'] = pd.to_datetime(df_processed['launched_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the datetime object, we create new features: the day of the week the campaign was launched and a flag for whether it was a weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new time-based features\n",
    "df_processed['day_of_week'] = df_processed['launched_at'].dt.dayofweek # Monday=0, Sunday=6\n",
    "df_processed['is_weekend'] = df_processed['day_of_week'].isin([5, 6]).astype(int)\n",
    "print(\"‚úÖ Engineered new features: 'day_of_week' and 'is_weekend'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. Clean and Prepare Target Variable**\n",
    "We filter the dataset to include only projects that were clearly 'successful' or 'failed', removing other states like 'canceled' or 'live'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'successful' and 'failed' projects\n",
    "valid_states = ['successful', 'failed']\n",
    "df_processed = df_processed[df_processed['binary_state'].isin(valid_states)]\n",
    "print(\"‚úÖ Filtered for valid states.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert our target variable, `binary_state`, into a numeric format where `1` represents a successful project and `0` represents a failed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target variable to numeric\n",
    "df_processed['binary_state'] = df_processed['binary_state'].map({'successful': 1, 'failed': 0})\n",
    "print(\"‚úÖ Target variable converted to numeric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Prepare Data for Modeling**\n",
    "Here, we select our features (`X`) and target (`y`) and split them for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1. Define Features (X) and Target (y)**\n",
    "\n",
    "First, we define our target variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "y = df_processed['binary_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify columns to be removed. Some are \"leaky\" (containing information that isn't available at the time of prediction, like `backers_count`) and others are simply unnecessary for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define leaky and unnecessary columns\n",
    "leaky_columns = ['usd_pledged', 'backers_count', 'spotlight', 'state']\n",
    "unnecessary_columns = [\n",
    "    'Unnamed: 0', 'id', 'blurb', 'name', 'currency', 'deadline', 'launched_at',\n",
    "    'goal', 'category_slug', 'location.country', 'slug', 'location_displayable_name',\n",
    "    'location_typelocation_country', 'location_statelocation_displayable_name'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our feature set `X` by dropping the target and the specified unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features 'X' by dropping target and specified columns\n",
    "X = df_processed.drop(columns=['binary_state'] + leaky_columns + unnecessary_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert all remaining categorical text features into numerical format using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode all remaining categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "print(f\"‚úÖ Data prepared for modeling. Total features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2. Split Data**\n",
    "We split the data into training (80%) and testing (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"‚úÖ Data split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Train and Evaluate the Model**\n",
    "We will train a Random Forest Classifier. A key improvement here is using `class_weight='balanced'`, which helps the model handle imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1. Train the Random Forest Model**\n",
    "\n",
    "Initialize the model with our chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with our key improvement: class_weight='balanced'\n",
    "rf_model_improved = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',  # Addresses class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "print(\"üå≥ Training the Random Forest model...\")\n",
    "rf_model_improved.fit(X_train, y_train)\n",
    "print(\"‚úÖ Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2. Evaluate Model Performance**\n",
    "Make predictions on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_rf_imp = rf_model_improved.predict(X_test)\n",
    "print(\"‚úÖ Predictions made on the test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy score\n",
    "print(\"\\n--- Evaluation of Improved Random Forest Model ---\")\n",
    "print(f\"Improved Model Accuracy: {accuracy_score(y_test, y_pred_rf_imp):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a classification report for a more detailed performance breakdown, including precision, recall, and F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf_imp, target_names=['Failed', 'Successful']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Analyze Feature Importance**\n",
    "Finally, let's see which features the model found most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature importances from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances and names from the trained model\n",
    "importances = rf_model_improved.feature_importances_\n",
    "feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame to make the data easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the features by importance to find the most influential ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by importance and get the top 20 features\n",
    "top_20_features = feature_importance_df.sort_values(by='importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the top 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=top_20_features)\n",
    "plt.title('Top 20 Most Important Features (Improved Model)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}